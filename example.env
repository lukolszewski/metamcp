NODE_ENV=production

# Postgres connection details
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_USER=metamcp_user
POSTGRES_PASSWORD=m3t4mcp
POSTGRES_DB=metamcp_db

# Database configuration (composed from above vars)
DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}

# Application URL configuration
# This is the public URL where your application will be accessible
APP_URL=http://localhost:12008
NEXT_PUBLIC_APP_URL=http://localhost:12008

# Auth configuration
BETTER_AUTH_SECRET=your-super-secret-key-change-this-in-production

# OIDC Provider Configuration (Optional)
# Uncomment and configure these variables to enable OpenID Connect authentication
# callback url is ${APP_URL}/api/auth/oauth2/callback/oidc
# Required for OIDC:
# OIDC_CLIENT_ID=your-oidc-client-id
# OIDC_CLIENT_SECRET=your-oidc-client-secret
# OIDC_DISCOVERY_URL=https://your-oidc-provider.com/.well-known/openid-configuration
# OIDC_AUTHORIZATION_URL=https://your-oidc-provider.com/auth

# Optional OIDC Configuration:
# OIDC_PROVIDER_ID=oidc
# OIDC_SCOPES=openid email profile
# OIDC_PKCE=true

# Docker networking fix
TRANSFORM_LOCALHOST_TO_DOCKER_INTERNAL=true

# AI Embeddings Configuration (OpenAI-compatible API)
# Embeddings enable semantic search for tools based on their descriptions
# Requires an OpenAI-compatible embeddings API endpoint

# API endpoint for embeddings service (must support OpenAI's /embeddings format)
# Default: http://localhost:11434/v1 (Ollama local installation)
# Examples:
#   - Ollama (local): http://localhost:11434/v1
#   - DeepInfra: https://api.deepinfra.com/v1/openai
#   - OpenAI: https://api.openai.com/v1
EMBEDDINGS_API_URL=http://localhost:11434/v1

# API key for the embeddings service
# Not required for local Ollama installations
# For DeepInfra, get your key at: https://deepinfra.com/dash/api_keys
EMBEDDINGS_API_KEY=your_api_key_here_if_required

# Embedding model to use
# Recommended: BAAI/bge-m3 (1024 dims, 8192 token context, multilingual, state-of-the-art)
# Alternatives: BAAI/bge-large-en-v1.5, jina-embeddings-v3
# Note: Model must be supported by your chosen API endpoint
EMBEDDING_MODEL=BAAI/bge-m3

# Search Configuration
DEFAULT_SEARCH_MODE=keyword  # Options: keyword (fast, basic) | embeddings (AI-powered, requires API key)
EMBEDDING_BATCH_SIZE=50      # How many tools to embed per API call (max 100, recommended 50)

# Smart Proxy Configuration (for embeddings mode)
SMART_PROXY_MAX_RESULTS=20         # Maximum tools to return in search results
SMART_PROXY_DROP_THRESHOLD=0.05    # Score difference threshold for filtering similar tools
SMART_PROXY_MIN_SCORE=0.4          # Minimum similarity score to include tool in results

# Truncation Configuration (prevents token limit errors during embedding)
EMBEDDING_TRUNCATE_ENABLED=true         # Enable automatic truncation of long descriptions
EMBEDDING_TRUNCATE_DELIMITER="\n"       # Split on newlines
EMBEDDING_TRUNCATE_OCCURRENCE=1         # Keep text before first delimiter occurrence
EMBEDDING_TRUNCATE_MIN_LENGTH=5         # Skip truncation if result would be < 5 chars
